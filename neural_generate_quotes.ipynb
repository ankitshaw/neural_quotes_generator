{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_generate_quotes.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "UKbh2R1C54LY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Upload data\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "u_V8psOnncIq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "\n",
        "\n",
        "# set seeds for reproducability\n",
        "from tensorflow import set_random_seed\n",
        "from numpy.random import seed\n",
        "set_random_seed(2)\n",
        "seed(1)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "  \n",
        "df = pd.read_csv('quotes_file.txt',sep='\\t',header= None, error_bad_lines=False)\n",
        "quotes = df.iloc[:,0].values.tolist()\n",
        "print(quotes[0:10])\n",
        "\n",
        "def clean_text(txt):\n",
        "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
        "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "    return txt \n",
        "\n",
        "corpus = [clean_text(x) for x in quotes]\n",
        "corpus[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1CPVoNYOpX9r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0zj3BNILwFl-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import sys\n",
        "import re\n",
        "%matplotlib inline\n",
        "\n",
        "n_samples = 200000\n",
        "max_len = 20\n",
        "\n",
        "def clean_sentences(sentences, lower = True):\n",
        "    n_sentences=[]\n",
        "    temp = ''\n",
        "    for sentence in sentences:\n",
        "#       print(sentence)\n",
        "      sentence = sentence.strip()\n",
        "      sentence = re.sub(r'[0-9#$%&*+():=?/]+', '', sentence)\n",
        "      if lower==True:\n",
        "        temp = \"\\t \"+sentence.lower()+ \" \\n\"\n",
        "      else:\n",
        "        temp = \"\\t \"+sentence+ \" \\n\"\n",
        "      n_sentences.append(temp)\n",
        "      temp=''\n",
        "    return n_sentences\n",
        "  \n",
        "cleaned_quotes = clean_sentences(quotes, lower=True)\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(split=' ', char_level=True)\n",
        "tokenizer.fit_on_texts(cleaned_quotes)\n",
        "sequences = tokenizer.texts_to_sequences(cleaned_quotes)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %d unique tokens.' % len(word_index))\n",
        "\n",
        "index2char = {}\n",
        "for ch in tokenizer.word_index:\n",
        "  index2char[tokenizer.word_index.get(ch)] = ch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4fV9C4HvwsKd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test = sequences[0]\n",
        "s = \"\"\n",
        "for temp in test:\n",
        "  if not temp==0:\n",
        "    s = s+ index2char[temp]\n",
        "    \n",
        "cleaned_quotes[0],s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5FhHqhWiwwyb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_split(data, lookback= 20, step = 5):\n",
        "  sentence = []\n",
        "  next_char = []\n",
        "  for d in data: \n",
        "    for i in range(lookback,len(d), step):\n",
        "      sentence.append(d[i-lookback:i])\n",
        "      next_char.append(d[i])\n",
        "  print(len(sentence))\n",
        "  return sentence, next_char\n",
        "\n",
        "sentence, next_char = generate_split(cleaned_quotes,lookback = max_len, step = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rmHLEqjGw0HN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_tokens = len(word_index)+1\n",
        "\n",
        "x = np.zeros((n_samples, max_len, n_tokens))\n",
        "y = np.zeros((n_samples, n_tokens))\n",
        "\n",
        "for i,s in enumerate(sentence[:n_samples]):\n",
        "  for t, char in enumerate(s):\n",
        "      x[i, t, word_index[char]] = 1\n",
        "  y[i, word_index[next_char[i]]] = 1\n",
        "  \n",
        "from keras.models import Sequential\n",
        "from keras import Model\n",
        "from keras.layers import Input, Embedding, LSTM, Dense, Flatten,Dropout, Conv1D,MaxPool1D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.models import load_model\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(LSTM(128, input_shape=(max_len, n_tokens),return_sequences= True))\n",
        "model2.add(Dropout(0.3))\n",
        "model2.add(LSTM(128))\n",
        "model2.add(Dropout(0.3))\n",
        "model2.add(Dense(n_tokens,activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NlIOkITSw_Et",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
        "model2.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YuKMrXn5xBrk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callbacks_list = [\n",
        "        keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='loss',\n",
        "            factor=0.1,\n",
        "            patience=1,\n",
        "        ),\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "            filepath=os.path.join('quotegen_test.h5'),\n",
        "            monitor='loss',\n",
        "            save_best_only=True,\n",
        "        ),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GGGiDB4nxLqD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HVceILjjxQNa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "history = model2.fit(x, y, batch_size=512, epochs=epochs, verbose =1, callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MFWbtDI3zYLG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature= 0.2):\n",
        "    preds = np.reshape(preds,preds.shape[-1])\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds+1e-25)/ temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1,preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def inference(sent):\n",
        "  string_length=20\n",
        "  string_revised=sent.ljust(string_length)\n",
        "  return string_revised"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4nPrkjLAzB4o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start_word=\"be\"\n",
        "inference_text = inference(start_word)\n",
        "\n",
        "for i in range(5):\n",
        "    sys.stdout.write(inference_text.strip()+\" \")\n",
        "    generated_text = inference_text[:20]+\"\"\n",
        "    for i in range(100):\n",
        "      sampled = np.zeros((1, max_len, n_tokens))\n",
        "      for t, char in enumerate(generated_text):\n",
        "          sampled[0, t, word_index[char]] = 1.\n",
        "      preds = model2.predict(sampled, verbose=0)[0]\n",
        "      next_index = sample(preds, 0.5)\n",
        "      next_char = index2char[next_index]\n",
        "      if next_char =='\\n':\n",
        "        \n",
        "        break\n",
        "      generated_text += next_char\n",
        "      generated_text = generated_text[1:]\n",
        "      sys.stdout.write(next_char)\n",
        "    print(\"\\n-\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wlO_ZWBCxQJz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# download trained model\n",
        "from google.colab import files\n",
        "files.download('quotegen_test.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m3SlScCgq_Qo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = load_model(os.path.join('quotegen_test.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e3oqYwZ7zcHr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}